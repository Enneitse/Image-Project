{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38a2615",
   "metadata": {},
   "source": [
    "# IMA205 Estienne GOIGOUX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6a62f2",
   "metadata": {},
   "source": [
    "<h3>Operational notebook</h3>\n",
    "<br>\n",
    "This notebook only runs the models and computes the predictions. You have to fill the IMAGE_DIR_TRAIN, panda_path_train, IMAGE_DIR_TEST, panda_path_test and run the main to get the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b5579e",
   "metadata": {},
   "source": [
    "The scientific approach has been to implement steps and come back to precedent to better the performance and this notebook does not represent the whole work or code. The steps are described in each notebook :\n",
    "<br>\n",
    "* Step 1 : data analysis, https://www.kaggle.com/code/estienneggx/1-dataset-analysis\n",
    "* Step 2 : Pre-processing and features extraction, https://www.kaggle.com/code/estienneggx/2-pre-processing-and-features-extraction\n",
    "* Step 3 : Building models, https://www.kaggle.com/code/estienneggx/3a-random-forest-on-tabular-data and https://www.kaggle.com/code/estienneggx/3b-cnn-on-images\n",
    "* Step 4 : Blending predictions https://www.kaggle.com/code/estienneggx/4-blending-models-and-final-predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74bbe41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL version : 9.0.1 cv2 version : 4.5.4 skimage version : 0.19.2 sklearn version : 1.0.2 scipy version : 1.7.3 pandas version : 1.3.5 matplotlib version : 3.5.1 seaborn version : 0.11.2 tensorflow version : 2.6.3 xgboost version : 1.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import skimage\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage.filters import sobel\n",
    "from skimage import morphology, measure, segmentation, exposure, color\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pandas_profiling as pdp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.compat.v1.logging import INFO, set_verbosity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('PIL version : 9.0.1',\n",
    "'cv2 version : 4.5.4',\n",
    "'skimage version : 0.19.2',\n",
    "'sklearn version : 1.0.2',\n",
    "'scipy version : 1.7.3',\n",
    "'pandas version : 1.3.5',\n",
    "'matplotlib version : 3.5.1',\n",
    "'seaborn version : 0.11.2',\n",
    "'tensorflow version : 2.6.3',\n",
    "'xgboost version : 1.6.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39a028a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dict = {\n",
    "    1 : 0.7005531, \n",
    "    2 : 0.24592265, \n",
    "    3 : 0.95261733, \n",
    "    4 : 3.64804147, \n",
    "    5 : 1.20674543, \n",
    "    6 : 13.19375, \n",
    "    7 : 12.56547619, \n",
    "    8 : 5.04219745\n",
    "}\n",
    "\n",
    "weights = [ 0.7005531, 0.24592265, 0.95261733, 3.64804147, 1.20674543, 13.19375, 12.56547619, 5.04219745]\n",
    "\n",
    "\n",
    "def rgb2yiq(imgArray):\n",
    "    '''\n",
    "    Simple mathematical operation for Adaptative thresholding implementation\n",
    "    '''\n",
    "    assert (imgArray.shape[2] == 3)\n",
    "    l = imgArray.shape[0]\n",
    "    L = imgArray.shape[1]\n",
    "    \n",
    "    YIQ = np.zeros((l, L, 3))\n",
    "    YIQ[:,:,0] = (0.299 * imgArray[:,:,0] + 0.587 * imgArray[:,:,1] + 0.114 * imgArray[:,:,2])\n",
    "    #YIQ[:,:,1] = 0.596 * imgArray[:,:,0] - 0.274 * imgArray[:,:,1] - 0.322 * imgArray[:,:,2]\n",
    "    #YIQ[:,:,2] = 0.211 * imgArray[:,:,0] - 0.523 * imgArray[:,:,1] + 0.312 * imgArray[:,:,2]\n",
    "    return np.asarray(YIQ)\n",
    "\n",
    "\n",
    "def invertPixelsMinusMean(blackAndWhite):\n",
    "    '''\n",
    "    Simple mathematical operation for Adaptative thresholding implementation\n",
    "    '''\n",
    "    inverted = (blackAndWhite.max() - blackAndWhite)\n",
    "    inverted = inverted - inverted.mean()\n",
    "    inverted[inverted < 0] = 0\n",
    "    \n",
    "    return inverted\n",
    "\n",
    "def averageFilter(img, filterSize):\n",
    "    if (filterSize == 0):\n",
    "        return img\n",
    "    else:\n",
    "        kernel = np.ones((filterSize,filterSize),np.float32)/(filterSize**2)\n",
    "        dst = cv2.filter2D(img,-1,kernel)\n",
    "    return dst\n",
    "\n",
    "# https://github.com/AndersDHenriksen/SanityChecker/blob/master/AllChecks.py\n",
    "def bwareafilt(mask, n=1, area_range=(0, np.inf)):\n",
    "    '''\n",
    "    Extracts the largest white area of binary img\n",
    "    '''\n",
    "    # For openCV > 3.0 this can be changed to: areas_num, labels = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    labels = measure.label(mask.astype('uint8'), background=0)\n",
    "    area_idx = np.arange(1, np.max(labels) + 1)\n",
    "    areas = np.array([np.sum(labels == i) for i in area_idx])\n",
    "    inside_range_idx = np.logical_and(areas >= area_range[0], areas <= area_range[1])\n",
    "    area_idx = area_idx[inside_range_idx]\n",
    "    areas = areas[inside_range_idx]\n",
    "    keep_idx = area_idx[np.argsort(areas)[::-1][0:n]]\n",
    "    kept_areas = areas[np.argsort(areas)[::-1][0:n]]\n",
    "    \n",
    "    if np.size(kept_areas) == 0:\n",
    "        kept_areas = np.array([0])\n",
    "    if n == 1:\n",
    "        kept_areas = kept_areas[0]\n",
    "    kept_mask = np.isin(labels, keep_idx)\n",
    "    \n",
    "    return kept_mask\n",
    "\n",
    "\n",
    "# Gives basic stats of the RGB channels of an image\n",
    "def getRGBstats(imPath):\n",
    "    '''\n",
    "    Computes basic stats of the histogram of an image\n",
    "    '''\n",
    "    img = np.array(Image.open(imPath))\n",
    "    redMean, redStd, redMedian = img[:,:,0].mean(), img[:,:,0].std(), np.median(img[:,:,1])\n",
    "    greenMean, greenStd, greenMedian = img[:,:,1].mean(), img[:,:,1].std(), np.median(img[:,:,1])\n",
    "    blueMean, blueStd, blueMedian = img[:,:,2].mean(), img[:,:,2].std(), np.median(img[:,:,2])\n",
    "    \n",
    "    return [redMean, redStd, redMedian, greenMean, greenStd, greenMedian, blueMean, blueStd, blueMedian]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5da23824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dull razor filter, removes hairs from pictures.\n",
    "# https://www.kaggle.com/code/antocad/siim-isic-image-preprocessing-dull-razor/notebook\n",
    "def dullrazor(img, lowbound=5, filterstruc=7, inpaintmat=5):\n",
    "\n",
    "    '''\n",
    "    Erases the hair from a skin image\n",
    "    '''\n",
    "    #grayscale\n",
    "    imgtmp1 = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    #applying a blackhat\n",
    "    filterSize =(filterstruc, filterstruc)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, filterSize) \n",
    "    imgtmp2 = cv2.morphologyEx(imgtmp1, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "    #0=skin and 255=hair\n",
    "    ret, mask = cv2.threshold(imgtmp2, lowbound, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    #inpainting\n",
    "    img_final = cv2.inpaint(img, mask, inpaintmat ,cv2.INPAINT_TELEA)\n",
    "\n",
    "    return img_final\n",
    "\n",
    "\n",
    "def AdaptiveTresholding(imgName, train = True, averageFilterSize = 0):\n",
    "    '''\n",
    "    Computes the segmentation of an image, given its associated ID and folder\n",
    "    imgName : str, id of the considered image\n",
    "    train : boolean, ables to tell if we are looking in the train or test set\n",
    "    showRazor : boolean, shows the step of the dullRazor algorithm is set to True\n",
    "    showLuminance : boolean, shows an image of the processed luminance if set to True\n",
    "    averageFilterSize : int, size of the averaging filter kernel if different than 0\n",
    "    compareSeg : prompts the comparison of the calculated and the true segmentation if set to True\n",
    "    '''\n",
    "    \n",
    "    if train:\n",
    "        imgPil = Image.open(IMAGE_DIR_TRAIN + '/' + imgName +'.jpg')\n",
    "    else:\n",
    "        imgPil = Image.open(IMAGE_DIR_TEST + '/' + imgName +'.jpg')\n",
    "        \n",
    "    arrayImg = np.asarray(imgPil)\n",
    "        \n",
    "    \n",
    "    # Step 1 : extract luminance, first channel of YIQ\n",
    "    luminance = rgb2yiq(dullrazor(arrayImg))[:,:,0]\n",
    "        \n",
    "    # Step 2 and 3 : apply transformations and denoise\n",
    "    processedLuminance = invertPixelsMinusMean(luminance)\n",
    "    processedLuminance = np.uint8(processedLuminance)\n",
    "    processedLuminance = cv2.fastNlMeansDenoising(processedLuminance)\n",
    "    averaged = averageFilter(processedLuminance, averageFilterSize)\n",
    "\n",
    "        \n",
    "    # bwareafilt extracts the largest white area of binary img\n",
    "    # Step 4 : Compute the binary image\n",
    "    binaryImage = bwareafilt(averaged > averaged.std() / 2, area_range = (0, averaged.shape[0]*averaged.shape[1]/2)) # Chooses the largest segmented part\n",
    "    \n",
    "    \n",
    "    # If the image border are black : new heuristically chosen segmentation method. The picture is first cropped then converted to black and white,\n",
    "    # The distance from the mean of the new image is computed and its edges are calculated. An averaging filter is then applied and the image is inverted before thresholding.\n",
    "    if (binaryImage[0:15,:]).all() and (binaryImage[:,0:15]).all() and (binaryImage[-16:-1,:]).all() and (binaryImage[:,-16:-1]).all():\n",
    "        \n",
    "        i=15\n",
    "        while((binaryImage[i,:]).all()):\n",
    "            i+=1\n",
    "        j=15\n",
    "        while((binaryImage[:,j]).all()):\n",
    "            j+=1\n",
    "            \n",
    "        if train:\n",
    "            imgPil = Image.open(IMAGE_DIR_TRAIN + '/' + imgName +'.jpg')\n",
    "        else:\n",
    "            imgPil = Image.open(IMAGE_DIR_TEST + '/' + imgName +'.jpg')\n",
    "\n",
    "            \n",
    "        image = np.array(imgPil)\n",
    "        grayscale = color.rgb2gray(image)\n",
    "        grayscale = grayscale[i:grayscale.shape[0]-i,j:grayscale.shape[1]-j]\n",
    "        \n",
    "        edge = sobel(grayscale)\n",
    "\n",
    "        meann = grayscale.mean()\n",
    "        processedImg = averageFilter(edge, 20)\n",
    "\n",
    "        processedImg = meann - abs(grayscale - meann)\n",
    "        processedImg = averageFilter(processedImg, 10)\n",
    "        processedImg = 1 - processedImg\n",
    "        \n",
    "        binaryImage = bwareafilt(processedImg > processedImg.mean(), area_range = (0, binaryImage.shape[0]*binaryImage.shape[1]/2))\n",
    "\n",
    "        \n",
    "    # Step 5 : filling holes\n",
    "    des = cv2.bitwise_not(binaryImage*255)\n",
    "    contour,hier = cv2.findContours(binaryImage*255,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contour:\n",
    "        cv2.drawContours(des,[cnt],0,255,-1)\n",
    "    \n",
    "    return des \n",
    "\n",
    "\n",
    "\n",
    "def getProps(anomalyName, train = True, seg = False):\n",
    "    '''\n",
    "    Returns the geometrical properties of an anomaly, given its associated ID and folder\n",
    "    anomalyName : str, id of the lesion\n",
    "    train : boolean, tells whether we are looking in the train or test set\n",
    "    seg : boolean, the segmentation performed by clinicians is selected when it exists, which is told with seg\n",
    "    '''\n",
    "    if seg:\n",
    "        if train:\n",
    "            smoothImg = np.asarray(Image.open(IMAGE_DIR_TRAIN + '/' + anomalyName + '_seg' +'.png'))\n",
    "        else:\n",
    "            smoothImg = np.asarray(Image.open(IMAGE_DIR_TEST + '/' + anomalyName + '_seg' +'.png'))\n",
    "\n",
    "    else:\n",
    "        segImg = AdaptiveTresholding(anomalyName, train = train, averageFilterSize = 5)\n",
    "        smoothImg = uniform_filter(segImg, size = 3)\n",
    "        \n",
    "        \n",
    "    # Extract geometrical properties of binary image using regionprops_table function\n",
    "    label_img = label(smoothImg)\n",
    "    properties = regionprops_table(label_img, properties=('area',\n",
    "    'axis_major_length',\n",
    "    'axis_minor_length',\n",
    "    'eccentricity',\n",
    "    'equivalent_diameter_area',\n",
    "    'extent',\n",
    "    'feret_diameter_max',\n",
    "    'inertia_tensor',\n",
    "    'moments_hu',\n",
    "    'perimeter'))\n",
    "    \n",
    "    return pd.DataFrame(properties).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba2c1515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(train = True):\n",
    "    \n",
    "    '''\n",
    "    Returns the dataframe containing the train or test features, \n",
    "    including the true classes if it is the train features.\n",
    "    '''\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    if train:\n",
    "        \n",
    "        train_path = IMAGE_DIR_TRAIN \n",
    "        trainFiles = [f for f in listdir(train_path) if isfile(join(train_path, f))]\n",
    "\n",
    "        dataFrame = pd.read_csv(panda_path_train)\n",
    "        \n",
    "        for ID in tqdm(dataFrame.ID):\n",
    "\n",
    "            if ((ID + '_seg.png') in trainFiles): # We take the given segmentation if it is given\n",
    "                seg = True\n",
    "            else:\n",
    "                seg = False\n",
    "\n",
    "            features.append(getProps(ID, True, seg))    \n",
    "            \n",
    "    else:\n",
    "        \n",
    "        test_path = IMAGE_DIR_TEST\n",
    "        testFiles = [f for f in listdir(test_path) if isfile(join(test_path, f))]\n",
    "\n",
    "        dataFrame = pd.read_csv(panda_path_test)\n",
    "\n",
    "        for ID in tqdm(dataFrame.ID):\n",
    "\n",
    "            if ((ID + '_seg.png') in testFiles): # We take the given segmentation if it is given\n",
    "                seg = True\n",
    "            else:\n",
    "                seg = False\n",
    "\n",
    "            features.append(getProps(ID, False, seg))    \n",
    "\n",
    "            \n",
    "    features = pd.DataFrame(features, columns = ['area',\n",
    "    'axis_major_length',\n",
    "    'axis_minor_length',\n",
    "    'eccentricity',\n",
    "    'equivalent_diameter_area',\n",
    "    'extent',\n",
    "    'feret_diameter_max',\n",
    "    'inertia_tensor-0-0',      \n",
    "    'inertia_tensor-0-1',\n",
    "    'inertia_tensor-1-0',\n",
    "    'inertia_tensor-1-1',\n",
    "    'moments_hu-0',\n",
    "    'moments_hu-1',\n",
    "    'moments_hu-2',\n",
    "    'moments_hu-3',\n",
    "    'moments_hu-4',\n",
    "    'moments_hu-5',\n",
    "    'moments_hu-6',\n",
    "    'perimeter'])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fc7e45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProcessedDF(train = True):\n",
    "    '''\n",
    "    Returns the processed dataframe, adding color stats and encoding categorical data\n",
    "    '''\n",
    "    colorStats = []\n",
    "    \n",
    "    if train:\n",
    "        \n",
    "        train_data = pd.read_csv(panda_path_train)\n",
    "        \n",
    "        # Get geometrical features\n",
    "        geoTrainFeatures = getFeatures()\n",
    "        \n",
    "        # Get colour features\n",
    "        for ID in tqdm(train_data.ID):\n",
    "            colorStats.append(getRGBstats(IMAGE_DIR_TRAIN + '/' + ID + '.jpg'))\n",
    "        X_train_color = pd.DataFrame(colorStats, columns = ['redMean','redStd','redMedian','greenMean','greenStd','greenMedian','blueMean','blueStd','blueMedian'])\n",
    "\n",
    "\n",
    "        geoTrainFeatures.index = np.arange(len(geoTrainFeatures))\n",
    "        X_train = pd.concat([train_data[['CLASS','SEX','AGE','POSITION']], geoTrainFeatures], axis = 1)\n",
    "        X_train = pd.get_dummies(X_train)\n",
    "        X_train = pd.concat([X_train_color,X_train], axis=1)\n",
    "\n",
    "        # SEX_female and SEX_male are complementary, we only need one\n",
    "        X_train['SEX_female'] = X_train['SEX_female'] - 0.5\n",
    "        \n",
    "        return X_train.drop('SEX_male', axis = 1)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        test_data = pd.read_csv(panda_path_test)\n",
    "        \n",
    "        # Get geometrical features\n",
    "        geoTestFeatures = getFeatures(train = False)\n",
    "\n",
    "        # Get colour features\n",
    "        for ID in tqdm(test_data.ID):\n",
    "            colorStats.append(getRGBstats(IMAGE_DIR_TEST + '/' + ID + '.jpg'))\n",
    "        X_test_color = pd.DataFrame(colorStats, columns = ['redMean','redStd','redMedian','greenMean','greenStd','greenMedian','blueMean','blueStd','blueMedian'])\n",
    "\n",
    "\n",
    "        geoTestFeatures.index = np.arange(len(geoTestFeatures))\n",
    "        X_test = pd.concat([test_data[['SEX','AGE','POSITION']], geoTestFeatures], axis = 1)\n",
    "        X_test = pd.get_dummies(X_test)\n",
    "        X_test = pd.concat([X_test_color,X_test], axis=1)\n",
    "\n",
    "        # SEX_female and SEX_male are complementary, we only need one\n",
    "        X_test['SEX_female'] = X_test['SEX_female'] - 0.5\n",
    "        \n",
    "        return X_test.drop('SEX_male', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cf1685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCNNstatsPreds():\n",
    "    '''\n",
    "    Trains a CNN from the vgg16 architecture and returns the predicted \n",
    "    probabilities for the 8 classes of the test set images.\n",
    "    '''\n",
    "    def preprocess(df):\n",
    "        for index, img in enumerate(df.ID):\n",
    "            img = img + '.jpg'\n",
    "            df.ID[index] = img\n",
    "        df.drop(['SEX','AGE','POSITION'], axis = 1, inplace = True)\n",
    "        df.ID = df.ID.astype('string')\n",
    "\n",
    "    def train_val_test_split(df, test_len=1000, val_ratio=0.5):\n",
    "        test_rows = (np.random.rand(1000)*df.shape[0]).astype(int)\n",
    "        test_df =  df.iloc[test_rows]\n",
    "        test_df = test_df.reset_index().drop(['index'], axis=1)\n",
    "        df.drop(test_rows, axis=0, inplace=True)\n",
    "        df = df.reset_index().drop(['index'], axis=1)\n",
    "        val_rows = (np.random.rand(int(val_ratio*df.shape[0]))*df.shape[0]).astype(int)\n",
    "        val_df = df.iloc[val_rows]\n",
    "        df.drop(val_rows, axis=0, inplace=True)\n",
    "        test_df = test_df.reset_index().drop(['index'], axis=1)\n",
    "        df = df.reset_index().drop(['index'], axis=1)\n",
    "        return df, val_df, test_df\n",
    "    \n",
    "    def vgg_model(input_shape=(224,224, 3)):\n",
    "        model = Sequential()\n",
    "        model.add(VGG16(include_top=False, weights='imagenet', input_shape=input_shape))\n",
    "\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        #model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Dense(1024))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu')) \n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(8, activation='sigmoid')) # Sigmoid for multiclass classification task\n",
    "        model.compile(optimizer=Adam(learning_rate=1e-4), loss_weights = weights, loss='CategoricalCrossentropy', metrics=['CategoricalAccuracy'])\n",
    "        print('Model has compiled')\n",
    "        return model\n",
    "    \n",
    "    vgg16_model = vgg_model(input_shape=(224,224, 3))\n",
    "    \n",
    "    \n",
    "    full_df = pd.read_csv(panda_path_train)\n",
    "    preprocess(full_df)\n",
    "    full_df = pd.get_dummies(full_df, columns =['CLASS'])\n",
    "    train_df, val_df, test_df = train_val_test_split(full_df)\n",
    "    labels=list(train_df.columns[1:])\n",
    "\n",
    "\n",
    "    weightsamples = []\n",
    "\n",
    "    for i in tqdm(range(len(train_df))):\n",
    "        j = ((train_df.iloc[i] == 1) * 1).values.argmax()\n",
    "        weightsamples.append(weights_dict[j])\n",
    "\n",
    "    train_df = pd.concat([pd.DataFrame(weightsamples, columns=['weights']), train_df], axis = 1)\n",
    "\n",
    "\n",
    "    def get_train_gen(df, img_path=IMAGE_DIR_TRAIN, target_size=(224,224)):\n",
    "        data_gen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                    horizontal_flip=True,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2)\n",
    "        return data_gen.flow_from_dataframe(dataframe=df, weight_col = 'weights', directory=img_path, \n",
    "                                          x_col='ID', y_col=list(df.columns)[2:],\n",
    "                                          batch_size=64, shuffle=True, class_mode='raw', \n",
    "                                          target_size=target_size)\n",
    "\n",
    "    def get_val_test_gen(val_df, test_df, img_path=IMAGE_DIR_TRAIN, target_size=(224,224)):\n",
    "        data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "        val = data_gen.flow_from_dataframe(dataframe=val_df, directory=img_path, \n",
    "                                          x_col='ID', y_col=list(val_df.columns)[1:],\n",
    "                                          batch_size=64, shuffle=True, class_mode='raw', \n",
    "                                          target_size=target_size)\n",
    "        test = data_gen.flow_from_dataframe(dataframe=test_df, directory=img_path, \n",
    "                                          x_col='ID', batch_size=1, shuffle=True, class_mode=None, \n",
    "                                          target_size=target_size)\n",
    "        return val, test\n",
    "\n",
    "    train_generator = get_train_gen(train_df)\n",
    "    valid_generator, test_generator = get_val_test_gen(val_df, test_df)\n",
    "\n",
    "    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "    STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    history = vgg16_model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, validation_data=valid_generator, validation_steps=STEP_SIZE_VALID, epochs=20)\n",
    "    full_df_test = pd.read_csv(panda_path_test)\n",
    "\n",
    "    for i in range(len(full_df_test.ID)):\n",
    "        full_df_test.ID[i] = full_df_test.ID[i] + '.jpg'\n",
    "    \n",
    "    data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    gen =  data_gen.flow_from_dataframe(dataframe=full_df_test,\n",
    "    directory= IMAGE_DIR_TEST,\n",
    "    x_col=\"ID\",\n",
    "    y_col=None,\n",
    "    batch_size=1,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(224,224))\n",
    "                              \n",
    "    return vgg16_model.predict_generator(gen)\n",
    "\n",
    "\n",
    "def getTreeStatsPreds(train_features, test_features):\n",
    "\n",
    "\n",
    "    Xtrain = train_features.drop('CLASS', axis = 1)\n",
    "    Xtest = test_features\n",
    "        \n",
    "    ytrain = train_features.CLASS - 1\n",
    "    \n",
    "    \n",
    "    training_weights = []\n",
    "    for classe in ytrain:\n",
    "        training_weights.append(weights_dict[classe + 1]) # We give weights to the training samples\n",
    "\n",
    "        \n",
    "    params = {'eta' : 0.5, 'subsample' : 0.9,\n",
    "    'learning_rate' : 10e-2, 'max_depth' : 5,\n",
    "    'n_estimators' : 300}\n",
    "    \n",
    "    \n",
    "    clf = xgb.XGBClassifier(eta = params['eta'], subsample = params['subsample'], learning_rate = params['learning_rate'],\n",
    "                            max_depth = params['max_depth'], n_estimators = model_params['n_estimators'])\n",
    "    clf.fit(Xtrain, ytrain, sample_weight = training_weights)\n",
    "\n",
    "    return pd.DataFrame(clf.predict_proba(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89c7a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR_TRAIN = os.path.join('../input/ima205-challenge-2022/Train/Train')\n",
    "panda_path_train = os.path.join('../input/ima205-challenge-2022/metadataTrain.csv')\n",
    "IMAGE_DIR_TEST = os.path.join('../input/ima205-challenge-2022/Test/Test')\n",
    "panda_path_test = os.path.join('../input/ima205-challenge-2022/metadataTest.csv')\n",
    "\n",
    "\n",
    "def main(IMAGE_DIR_TRAIN = IMAGE_DIR_TRAIN, panda_path_train = panda_path_train,\n",
    "         IMAGE_DIR_TEST = IMAGE_DIR_TEST, panda_path_test = panda_path_test):\n",
    "    \n",
    "    train_features = getProcessedDF(train = True)\n",
    "    test_features = getProcessedDF(train = False)\n",
    "\n",
    "    treeStatsPreds = getTreeStatsPreds(train_features, test_features)\n",
    "    CNNstatsPreds = getCNNstatsPreds()\n",
    "    \n",
    "    for i in tqdm(range(6333)):\n",
    "        CNNstatsPreds = CNNstatsPreds.iloc[i][[0,1,2,3,4,5,6,7]].values / CNNstatsPreds.iloc[i][[0,1,2,3,4,5,6,7]].values.sum() # CNN stats are not probabilities, we convert them\n",
    "        treeStatsPreds = treeStatsPreds.iloc[i][[1,2,3,4,5,6,7,8]].values\n",
    "        preds.append((0.8*CNNstatsPreds + 0.2*treeStatsPreds).argmax() + 1) # Let's give CNN_Stats more importance since it has a better accuracy*\n",
    "        \n",
    "    submission = pd.concat([test_features.ID, pd.DataFrame(preds)], axis = 1)\n",
    "    submission.columns = ['ID', 'CLASS']\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6458ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = main()\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
